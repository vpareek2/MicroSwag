Okay, let's lay out a concrete plan to integrate the RWKV implementation into your NanoTitan codebase, focusing on adapting the model to fit your existing framework for a fair comparison.

Goal: Make the RWKV model work within your train.py loop, using your config.py, dataloader.py, and optimization.py.

Phase 1: Code Setup and Initial Adaptation

File Organization:
Create directory: models/rwkv/
Create subdirectory: models/rwkv/cuda/
Copy the content of the model.py you provided into models/rwkv/model.py.
Save the C++ code (wkv7_op.cpp) into models/rwkv/cuda/wkv7_op.cpp.
Save the CUDA code (wkv7_cuda.cu) into models/rwkv/cuda/wkv7_cuda.cu.
(Discard the other provided files: trainer.py, dataset.py, binidx.py, make_data.py, .sh scripts - we won't use their training/data logic).
Adapt models/rwkv/model.py (Core Model Definition):
Imports: Remove PyTorch Lightning imports (pytorch_lightning, rank_zero_info, rank_zero_only, DeepSpeedStrategy). Keep torch, nn, F, os, math, gc, importlib, inspect. Add from dataclasses import dataclass if needed for config handling.
Class Definition: Change class RWKV(pl.LightningModule): to class RWKV(nn.Module):.
__init__(self, args):
Change the input signature to __init__(self, config) where config will be an instance of your RWKVConfig dataclass (defined later).
Replace all occurrences of args. with config. (e.g., args.n_layer becomes config.n_layer).
Store the config: self.config = config.
Remove any lines related to self.trainer or deepspeed strategies within __init__.
Keep all layer definitions (self.emb, self.blocks, self.ln_out, self.head).
forward(self, idx):
This method seems largely compatible.
Replace args. with self.config..
Handle args.grad_cp: Decide if you want to control gradient checkpointing via the config or manage it externally in your train.py. If externally, remove the if args.grad_cp == 1: block here. If via config, keep it as if self.config.grad_cp == 1:.
Remove the deepspeed.checkpointing.checkpoint call if you handle grad checkpointing differently, or ensure deepspeed is imported if you keep it.
CUDA Kernel Section: Keep the load() call and the RUN_CUDA_RWKV7g function definition. The environment variables (RWKV_HEAD_SIZE, RWKV_MY_TESTING, RWKV_JIT_ON) will be set externally in train.py before this module is imported/used.
Remove Unused Methods/Classes: Delete training_step, training_step_end, generate_init_weight, L2Wrap, and the original configure_optimizers method (we'll add a new one). Delete helper classes/functions related only to the Lightning training loop or data loading if any exist beyond the main RWKV class.
Add New configure_optimizers: Add the compatible method inside the RWKV class as detailed in the previous response (using self.config and matching the signature expected by your optimization.py).
Define Configurations in config.py:
Add the RWKVConfig and RWKVTrainingConfig dataclasses as defined in the previous response.
Crucially: Ensure RWKVConfig.vocab_size matches your project's tokenizer (50304).
Ensure RWKVConfig.ctx_len matches BaseTrainingConfig.sequence_length (1024).
Set RWKVConfig.n_layer and RWKVConfig.n_embd to target your ~124M parameter budget (e.g., L12/D768 might be close).
Set RWKVConfig.head_size = 64 as required by the v7 CUDA kernel.
For RWKVTrainingConfig, use the same learning_rate, min_lr_ratio, warmup_steps, max_steps, betas, eps, weight_decay as your other models (like GPT2TrainingConfig) to ensure fair comparison. Ignore the specific LR/WD values mentioned in the RWKV scripts for now.
Update the ModelConfig class's get_model_specific_config and get_model_training_config methods to include elif self.model_type == "rwkv":.
Phase 2: Integration with Training Loop

Update train.py:
Imports: Add import models.rwkv, import os, import sys.
Set Environment Variables: Before the model creation block (before model = ...), add:
if args.model == "rwkv":
    print("Setting environment variables for RWKV...")
    model_config = config.model_specific # Get the RWKVConfig instance
    os.environ["RWKV_HEAD_SIZE"] = str(model_config.head_size)
    os.environ["RWKV_MY_TESTING"] = "x070" # Specific version needed for the CUDA kernel
    os.environ["RWKV_JIT_ON"] = "1" # Assuming standard PyTorch JIT
    # Optional: Add model path to sys.path if kernel compilation has issues finding cuda files
    # rwkv_model_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), 'models', 'rwkv'))
    # if rwkv_model_dir not in sys.path:
    #     sys.path.append(rwkv_model_dir)
    print(f"  RWKV_HEAD_SIZE={os.environ['RWKV_HEAD_SIZE']}")
    print(f"  RWKV_MY_TESTING={os.environ['RWKV_MY_TESTING']}")
    print(f"  RWKV_JIT_ON={os.environ['RWKV_JIT_ON']}")
content_copy
download
Use code with caution.
Python
Model Creation Helper: Add the create_rwkv_from_config helper function to the bottom of models/rwkv/model.py (as defined in the previous response). Make sure it correctly creates the args namespace object from the NanoTitan config.
Instantiate Model: In the model creation sections (both resume and fresh start), add the elif block:
# ... inside the try/except block for resuming or the 'else' for fresh start
elif args.model == "rwkv":
    # Ensure config is fully initialized before calling create_...
    # If resuming, config might come from checkpoint, ensure it's compatible.
    # If fresh start, config is already initialized.
    if 'checkpoint' in locals() and 'config' in checkpoint:
         # If loading from checkpoint, potentially use loaded config?
         # Or better: Ensure the checkpoint config matches current RWKVConfig structure.
         # For simplicity now, assume we create based on current script's config.
         # model_cfg_from_ckpt = checkpoint['config'] # Example if needed
         pass # Decide how to handle config mismatch on resume if necessary
    model = models.rwkv.create_rwkv_from_config(config) # Pass the main Config object
# ...
```    *   **Gradient Checkpointing:** If you removed the logic from `RWKV.forward`, you might need to wrap the `model(x, y)` call in `train.py` with `torch.utils.checkpoint.checkpoint` if `config.system.use_grad_checkpointing` (or similar) is true, specifically for RWKV if it needs it more than others.
content_copy
download
Use code with caution.
Python
Phase 3: Testing and Verification

CUDA Kernel Compilation:
Run python train.py --model rwkv on a machine with nvcc (CUDA toolkit) and a C++ compiler (g++) installed.
The first time import models.rwkv.model happens (indirectly via create_rwkv_from_config), the load() command should trigger the compilation.
Debug: Carefully watch the output for compilation errors. Common issues include missing headers, incorrect paths, compiler incompatibilities, or missing CUDA libraries. Ensure the load() command can find models/rwkv/cuda/wkv7_op.cpp and models/rwkv/cuda/wkv7_cuda.cu relative to where model.py is.
If successful, subsequent runs shouldn't recompile unless the source files change.
Initialization Test:
Once the kernel compiles, check if the script proceeds to initialize the RWKV model without Python errors (e.g., AttributeError if config mapping is wrong).
Optimizer Test:
Check the console output for the "RWKV Optimizer: Found..." logs printed by the configure_optimizers method. Verify it's grouping parameters as expected.
Single Step Test:
Allow the script to run for one training step.
Check for runtime errors during the forward pass (shape mismatches, CUDA errors from the kernel) or backward pass.
Verify that a loss value is calculated and printed.
Parameter Count Verification:
Add a line after model creation in train.py (if master_process) to print sum(p.numel() for p in model.parameters() if p.requires_grad).
Adjust RWKVConfig.n_layer / RWKVConfig.n_embd until the parameter count is close to your 124M target.
This plan breaks the integration into manageable steps, focusing on adapting the core model first, then integrating it with your existing training infrastructure.
