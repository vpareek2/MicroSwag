{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev Notebook for optimizing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added '/root/MicroSwag' to sys.path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/MicroSwag/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful.\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "Number of GPUs: 2\n",
      "  GPU 0: NVIDIA GeForce RTX 3090\n",
      "  GPU 1: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Add the parent directory ('pretrain') to the Python path\n",
    "# This allows importing modules like config, utils, models\n",
    "notebook_dir = os.getcwd()\n",
    "pretrain_dir = os.path.dirname(notebook_dir)\n",
    "if pretrain_dir not in sys.path:\n",
    "    sys.path.append(pretrain_dir)\n",
    "print(f\"Added '{pretrain_dir}' to sys.path\")\n",
    "\n",
    "# Import your modules\n",
    "from config import Config\n",
    "from utils import dataloader, distributed, optimization, evaluation, hellaswag # Ensure hellaswag is importable if needed directly, or rely on evaluation\n",
    "from models import gpt2 # Import the specific model module\n",
    "import pretrain.train\n",
    "\n",
    "print(\"Imports successful.\")\n",
    "# Verify GPU availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  Model Type: gpt2\n",
      "  Total Batch Size: 524288\n",
      "  Micro Batch Size: 64\n",
      "  Sequence Length: 1024\n",
      "  Data Root: edu_fineweb10B\n",
      "  Log Dir: log\n",
      "  Use Compile: True\n",
      "  Absolute Data Root: /root/MicroSwag/edu_fineweb10B\n",
      "  Absolute Log Dir: /root/MicroSwag/log\n"
     ]
    }
   ],
   "source": [
    "# Load the default configuration\n",
    "config = Config()\n",
    "# You can override specific settings here if needed for testing, e.g.:\n",
    "# config.model_training.micro_batch_size = 4\n",
    "# config.system.use_compile = False # Disable compile for easier debugging if needed\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Model Type: {config.model.model_type}\")\n",
    "print(f\"  Total Batch Size: {config.model_training.total_batch_size}\")\n",
    "print(f\"  Micro Batch Size: {config.model_training.micro_batch_size}\")\n",
    "print(f\"  Sequence Length: {config.model_training.sequence_length}\")\n",
    "print(f\"  Data Root: {config.data.data_root}\") # Make sure this matches your structure\n",
    "print(f\"  Log Dir: {config.system.log_dir}\")\n",
    "print(f\"  Use Compile: {config.system.use_compile}\")\n",
    "\n",
    "# Ensure the data root exists relative to the pretrain directory\n",
    "config.data.data_root = os.path.join(pretrain_dir, config.data.data_root)\n",
    "print(f\"  Absolute Data Root: {config.data.data_root}\")\n",
    "assert os.path.isdir(config.data.data_root), f\"Data root directory not found: {config.data.data_root}\"\n",
    "\n",
    "# Ensure log dir exists relative to the pretrain directory\n",
    "config.system.log_dir = os.path.join(pretrain_dir, config.system.log_dir)\n",
    "print(f\"  Absolute Log Dir: {config.system.log_dir}\")\n",
    "os.makedirs(config.system.log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Distributed config:\n",
      "  ddp: False\n",
      "  ddp_rank: 0\n",
      "  ddp_local_rank: 0\n",
      "  ddp_world_size: 1\n",
      "  device: cuda\n",
      "  master_process: True\n",
      "  device_type: cuda\n",
      "\n",
      "Set float32 matmul precision to: high\n"
     ]
    }
   ],
   "source": [
    "# In a notebook, RANK env vars aren't set, so this will default to non-DDP\n",
    "dist_config = distributed.setup_distributed()\n",
    "\n",
    "print(\"Distributed config:\")\n",
    "for key, value in dist_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "device = dist_config[\"device\"]\n",
    "device_type = dist_config[\"device_type\"]\n",
    "master_process = dist_config[\"master_process\"]\n",
    "\n",
    "# Set precision (as done in train.py)\n",
    "torch.set_float32_matmul_precision(config.system.float32_matmul_precision)\n",
    "print(f\"\\nSet float32 matmul precision to: {config.system.float32_matmul_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up data loaders...\n",
      "found 99 shards for split train\n",
      "found 1 shards for split val\n",
      "Data loaders initialized.\n",
      "Fetching one train batch...\n",
      "  Train batch shapes: x=torch.Size([4, 512]), y=torch.Size([4, 512])\n",
      "  Train batch types: x=torch.int64, y=torch.int64\n",
      "Fetching one validation batch...\n",
      "  Val batch shapes: x=torch.Size([64, 1024]), y=torch.Size([64, 1024])\n",
      "  Val batch types: x=torch.int64, y=torch.int64\n",
      "  Train x min/max: 0, 50256\n",
      "  Train y min/max: 0, 50256\n",
      "\n",
      "Testing loader checkpointing...\n",
      "  Initial train loader checkpoint: {'current_shard': 0, 'current_position': 2048}\n",
      "  Train loader checkpoint after 1 batch: {'current_shard': 0, 'current_position': 4096}\n",
      "  Train loader checkpoint after reset: {'current_shard': 0, 'current_position': 0}\n",
      "  Train loader checkpoint after set: {'current_shard': 0, 'current_position': 2048}\n",
      "  Loader checkpointing seems functional.\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up data loaders...\")\n",
    "\n",
    "# Use process_rank 0 and num_processes 1 for non-DDP test\n",
    "train_loader = dataloader.DataLoader(\n",
    "    B=4,\n",
    "    T=512,\n",
    "    process_rank=dist_config[\"ddp_rank\"], # Should be 0\n",
    "    num_processes=dist_config[\"ddp_world_size\"], # Should be 1\n",
    "    split=\"train\",\n",
    "    data_root=config.data.data_root,\n",
    "    master_process=master_process\n",
    ")\n",
    "\n",
    "val_loader = dataloader.DataLoader(\n",
    "    B=config.model_training.micro_batch_size,\n",
    "    T=config.model_training.sequence_length,\n",
    "    process_rank=dist_config[\"ddp_rank\"], # Should be 0\n",
    "    num_processes=dist_config[\"ddp_world_size\"], # Should be 1\n",
    "    split=\"val\",\n",
    "    data_root=config.data.data_root,\n",
    "    master_process=master_process\n",
    ")\n",
    "\n",
    "print(\"Data loaders initialized.\")\n",
    "\n",
    "# Fetch one batch from each loader\n",
    "print(\"Fetching one train batch...\")\n",
    "x_train, y_train = train_loader.next_batch()\n",
    "print(f\"  Train batch shapes: x={x_train.shape}, y={y_train.shape}\")\n",
    "print(f\"  Train batch types: x={x_train.dtype}, y={y_train.dtype}\")\n",
    "\n",
    "\n",
    "print(\"Fetching one validation batch...\")\n",
    "x_val, y_val = val_loader.next_batch()\n",
    "print(f\"  Val batch shapes: x={x_val.shape}, y={y_val.shape}\")\n",
    "print(f\"  Val batch types: x={x_val.dtype}, y={y_val.dtype}\")\n",
    "\n",
    "# Check token range (optional)\n",
    "print(f\"  Train x min/max: {x_train.min()}, {x_train.max()}\")\n",
    "print(f\"  Train y min/max: {y_train.min()}, {y_train.max()}\")\n",
    "\n",
    "# Test loader checkpointing (optional)\n",
    "print(\"\\nTesting loader checkpointing...\")\n",
    "cp = train_loader.get_loader_checkpoint()\n",
    "print(f\"  Initial train loader checkpoint: {cp}\")\n",
    "# Advance position by fetching another batch\n",
    "_, _ = train_loader.next_batch()\n",
    "cp_after = train_loader.get_loader_checkpoint()\n",
    "print(f\"  Train loader checkpoint after 1 batch: {cp_after}\")\n",
    "# Reset and check again\n",
    "train_loader.reset()\n",
    "cp_reset = train_loader.get_loader_checkpoint()\n",
    "print(f\"  Train loader checkpoint after reset: {cp_reset}\")\n",
    "# Set back to original state\n",
    "train_loader.set(cp)\n",
    "cp_set = train_loader.get_loader_checkpoint()\n",
    "print(f\"  Train loader checkpoint after set: {cp_set}\")\n",
    "assert cp_set['current_shard'] == cp['current_shard']\n",
    "assert cp_set['current_position'] == cp['current_position']\n",
    "print(\"  Loader checkpointing seems functional.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model...\n",
      "GPT-2 model with 124.5M parameters\n",
      "Model 'gpt2' created.\n",
      "Wrapping model (device='cuda', use_compile=True)...\n",
      "Model wrapped successfully.\n",
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the model...\")\n",
    "# Use the specific model's creation logic if available, or direct instantiation\n",
    "if config.model.model_type == \"gpt2\":\n",
    "     # Option 1: Use helper if defined correctly in gpt2.py\n",
    "     # model_instance = gpt2.create_gpt_from_config(config) # Make sure this function exists and works\n",
    "     # Option 2: Directly use the class\n",
    "     model_instance = gpt2.GPT(config.model_specific)\n",
    "else:\n",
    "     raise ValueError(f\"Unsupported model type for testing: {config.model.model_type}\")\n",
    "\n",
    "print(f\"Model '{config.model.model_type}' created.\")\n",
    "# print(model_instance) # Optional: Print model structure\n",
    "\n",
    "# Wrap model (moves to device, applies compile if enabled)\n",
    "print(f\"Wrapping model (device='{device}', use_compile={config.system.use_compile})...\")\n",
    "# This might take a minute if compilation is enabled\n",
    "model, raw_model = distributed.wrap_model_for_distributed(\n",
    "    model_instance,\n",
    "    device,\n",
    "    dist_config[\"ddp\"],\n",
    "    dist_config[\"ddp_local_rank\"],\n",
    "    use_compile=False\n",
    ")\n",
    "print(\"Model wrapped successfully.\")\n",
    "\n",
    "# Check model device\n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating optimizer...\n",
      "num decayed parameter tensors: 50, with 124,354,560 parameters\n",
      "num non-decayed parameter tensors: 98, with 121,344 parameters\n",
      "using fused AdamW: True\n",
      "Optimizer created.\n",
      "Creating LR scheduler function...\n",
      "LR scheduler function created.\n",
      "  LR at step 0: 8.3916e-07\n",
      "  LR at step 357: 3.0042e-04\n",
      "  LR at step 715: 6.0000e-04\n",
      "  LR at step 19073: 6.0000e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating optimizer...\")\n",
    "optimizer = optimization.create_optimizer(\n",
    "    raw_model, # Use the unwrapped model for optimizer configuration\n",
    "    config,\n",
    "    device_type,\n",
    "    master_process=master_process\n",
    ")\n",
    "print(\"Optimizer created.\")\n",
    "# print(optimizer) # Optional: Print optimizer details\n",
    "\n",
    "print(\"Creating LR scheduler function...\")\n",
    "get_lr = optimization.get_lr_scheduler(config, optimizer)\n",
    "print(\"LR scheduler function created.\")\n",
    "\n",
    "# Test LR scheduler for a few steps\n",
    "print(f\"  LR at step 0: {get_lr(0):.4e}\")\n",
    "print(f\"  LR at step {config.model_training.warmup_steps // 2}: {get_lr(config.model_training.warmup_steps // 2):.4e}\")\n",
    "print(f\"  LR at step {config.model_training.warmup_steps}: {get_lr(config.model_training.warmup_steps):.4e}\")\n",
    "print(f\"  LR at step {config.model_training.max_steps}: {get_lr(config.model_training.max_steps):.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing a single training step...\n",
      "  Input shapes on device 'cuda': x=torch.Size([4, 512]), y=torch.Size([4, 512])\n",
      "  Forward pass successful. Loss: 10.9247 (Time: 0.33s)\n",
      "  Logits shape: torch.Size([4, 512, 50304])\n",
      "  Backward pass successful. (Time: 0.05s)\n",
      "  Gradient norm before clip (if any): 19.8210\n",
      "  Optimizer step successful. (Time: 0.01s)\n",
      "Single training step test complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing a single training step...\")\n",
    "model.train() # Set model to training mode\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Get a batch and move to device\n",
    "x, y = train_loader.next_batch()\n",
    "x, y = x.to(device), y.to(device)\n",
    "print(f\"  Input shapes on device '{device}': x={x.shape}, y={y.shape}\")\n",
    "\n",
    "# Forward pass - CHANGE DTYPE HERE\n",
    "t0 = time.time()\n",
    "# Use float16 instead of bfloat16\n",
    "with torch.autocast(device_type=device_type, dtype=torch.float16): # <--- CHANGE HERE\n",
    "    logits, loss = model(x, y)\n",
    "t1 = time.time()\n",
    "print(f\"  Forward pass successful. Loss: {loss.item():.4f} (Time: {t1-t0:.2f}s)\")\n",
    "print(f\"  Logits shape: {logits.shape}\")\n",
    "\n",
    "# Backward pass\n",
    "t0 = time.time()\n",
    "# Loss needs to be float32 for backward typically, autocast handles the ops\n",
    "# but the loss scaling might need float32 accumulation outside autocast\n",
    "# However, PyTorch's backward usually handles this correctly with autocast.\n",
    "loss.backward()\n",
    "t1 = time.time()\n",
    "print(f\"  Backward pass successful. (Time: {t1-t0:.2f}s)\")\n",
    "\n",
    "# Gradient clipping (optional but good practice)\n",
    "norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.model_training.grad_clip)\n",
    "print(f\"  Gradient norm before clip (if any): {norm:.4f}\")\n",
    "\n",
    "# Optimizer step\n",
    "t0 = time.time()\n",
    "optimizer.step()\n",
    "t1 = time.time()\n",
    "print(f\"  Optimizer step successful. (Time: {t1-t0:.2f}s)\")\n",
    "\n",
    "print(\"Single training step test complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing validation step logic...\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 12.28 GiB. GPU 0 has a total capacity of 23.57 GiB of which 7.93 GiB is free. Process 2243306 has 15.63 GiB memory in use. Of the allocated memory 14.97 GiB is allocated by PyTorch, and 356.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Use float16 as decided before for 3090 compatibility\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39mdevice_type, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16): \u001b[38;5;66;03m# <--- Use float16\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m val_loss_accum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;66;03m# Accumulate loss\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m master_process \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m: \u001b[38;5;66;03m# Print first few losses\u001b[39;00m\n",
      "File \u001b[0;32m~/MicroSwag/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MicroSwag/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/MicroSwag/pretrain/models/gpt2.py:114\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    112\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits, loss\n",
      "File \u001b[0;32m~/MicroSwag/.venv/lib/python3.10/site-packages/torch/nn/functional.py:3494\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3493\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3501\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 12.28 GiB. GPU 0 has a total capacity of 23.57 GiB of which 7.93 GiB is free. Process 2243306 has 15.63 GiB memory in use. Of the allocated memory 14.97 GiB is allocated by PyTorch, and 356.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "print(\"Testing validation step logic...\")\n",
    "# --- This logic is adapted directly from the validate function in train.py ---\n",
    "model.eval() # Set model to evaluation mode\n",
    "val_loader.reset() # Reset the validation loader\n",
    "\n",
    "val_steps = 5 # Use fewer steps for a quick test in the notebook\n",
    "val_loss_accum = 0.0\n",
    "ddp = dist_config[\"ddp\"] # Get ddp flag from dist_config\n",
    "\n",
    "t0 = time.time()\n",
    "with torch.no_grad(): # Ensure no gradients are calculated\n",
    "    for i in range(val_steps):\n",
    "        x, y = val_loader.next_batch()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        # Use float16 as decided before for 3090 compatibility\n",
    "        with torch.autocast(device_type=device_type, dtype=torch.float16): # <--- Use float16\n",
    "            logits, loss = model(x, y)\n",
    "        val_loss_accum += loss.detach() # Accumulate loss\n",
    "        if master_process and i < 3: # Print first few losses\n",
    "             print(f\"  Validation step {i+1}/{val_steps}, Batch Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Average the accumulated loss\n",
    "    val_loss_accum /= val_steps\n",
    "\n",
    "# In a real DDP run, we would average across processes.\n",
    "# Here, ddp is False, so all_reduce_mean is essentially a no-op, but we include it for completeness.\n",
    "val_loss = distributed.all_reduce_mean(val_loss_accum, ddp)\n",
    "\n",
    "t1 = time.time()\n",
    "# --- End of adapted logic ---\n",
    "\n",
    "print(f\"\\nValidation logic test complete (over {val_steps} steps).\")\n",
    "# val_loss is a tensor if not reduced, get item if it's a scalar tensor\n",
    "final_val_loss = val_loss.item() if isinstance(val_loss, torch.Tensor) else val_loss\n",
    "print(f\"  Average Validation Loss: {final_val_loss:.4f}\")\n",
    "print(f\"  Validation Time: {t1 - t0:.2f}s\")\n",
    "\n",
    "# Switch back to train mode potentially for subsequent cells if needed, though HellaSwag uses eval()\n",
    "model.train() # Or keep as model.eval() if only doing HellaSwag next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you fixed the duplicate get_most_likely_row function!\n",
    "print(\"Testing HellaSwag evaluation...\")\n",
    "model.eval() # Ensure model is in eval mode\n",
    "\n",
    "t0 = time.time()\n",
    "# Note: This iterates through the *entire* HellaSwag val set (10042 examples)\n",
    "# In a non-DDP setup (like this notebook), this rank will process all examples.\n",
    "# This might take a few minutes.\n",
    "results = evaluation.evaluate_hellaswag(\n",
    "    model,\n",
    "    device,\n",
    "    device_type,\n",
    "    dist_config[\"ddp_rank\"],\n",
    "    dist_config[\"ddp_world_size\"],\n",
    "    distributed # Pass the distributed utils module\n",
    ")\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"HellaSwag evaluation complete.\")\n",
    "print(f\"  Accuracy: {results['accuracy']:.4f} ({results['correct']}/{results['total']})\")\n",
    "print(f\"  HellaSwag Eval Time: {t1 - t0:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cleaning up distributed context (no-op in non-DDP)...\")\n",
    "distributed.cleanup_distributed(dist_config[\"ddp\"])\n",
    "print(\"Cleanup called.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
